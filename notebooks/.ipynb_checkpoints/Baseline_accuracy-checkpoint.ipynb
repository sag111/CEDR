{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6150adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6544bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "029d602e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0010b693b19441c9fc90d249a86cf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c0b5665ecd4dcc8014ac9677c9e3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cedr/enriched (download: 1.74 MiB, generated: 5.70 MiB, post-processed: Unknown size, total: 7.44 MiB) to /home/aleksandr/.cache/huggingface/datasets/cedr/enriched/0.1.1/715639b8fdb9faa0063aa2b7b1b5283518253c296619c1646aed66583406acf7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1380e704a5b44cda35989562ac5783a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cedr downloaded and prepared to /home/aleksandr/.cache/huggingface/datasets/cedr/enriched/0.1.1/715639b8fdb9faa0063aa2b7b1b5283518253c296619c1646aed66583406acf7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cedr (/home/aleksandr/.cache/huggingface/datasets/cedr/enriched/0.1.1/715639b8fdb9faa0063aa2b7b1b5283518253c296619c1646aed66583406acf7)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "train_df = load_dataset('sagteam/cedr', name='enriched', split='train')\n",
    "test_df = load_dataset('sagteam/cedr', name='enriched', split='test')\n",
    "\n",
    "with open('../data/emo_lexicon.json') as f:\n",
    "    emo_lexicon_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e0feb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random approach:\n",
      "\n",
      "Emotion \"surprise\":\n",
      "mic.: 0.51;\t mac.:0.41\n",
      "\n",
      "Emotion \"fear\":\n",
      "mic.: 0.49;\t mac.:0.39\n",
      "\n",
      "Emotion \"joy\":\n",
      "mic.: 0.49;\t mac.:0.44\n",
      "\n",
      "Emotion \"sadness\":\n",
      "mic.: 0.49;\t mac.:0.44\n",
      "\n",
      "Emotion \"anger\":\n",
      "mic.: 0.5;\t mac.:0.39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random approach\n",
    "\n",
    "print('Random approach:\\n')\n",
    "\n",
    "for emo_label in emo_lexicon_dict.keys():\n",
    "    true_y = []\n",
    "    \n",
    "    for sample in test_df:\n",
    "        if emo_label in sample['labels']:\n",
    "            true_y.append(1)\n",
    "        else:\n",
    "            true_y.append(0)\n",
    "            \n",
    "    # The emotion label is chosen randomly for each sentence\n",
    "    pred_y = np.random.randint(0,2,len(test_df))\n",
    "    \n",
    "    # The accuracy of the obtained models is measured with the F1 metric\n",
    "    p_micro, r_micro, f_micro, _ = metrics.precision_recall_fscore_support(true_y, pred_y, average=\"micro\")\n",
    "    p_macro, r_macro, f_macro, _ = metrics.precision_recall_fscore_support(true_y, pred_y, average=\"macro\")\n",
    "    \n",
    "    print(f'Emotion \"{emo_label}\":')\n",
    "    print(f'mic.: {round(f_micro, 2)};\\t mac.:{round(f_macro, 2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ac44e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon approach:\n",
      "\n",
      "Emotion \"surprise\":\n",
      "mic.: 0.88;\t mac.:0.76\n",
      "\n",
      "Emotion \"fear\":\n",
      "mic.: 0.83;\t mac.:0.68\n",
      "\n",
      "Emotion \"joy\":\n",
      "mic.: 0.83;\t mac.:0.73\n",
      "\n",
      "Emotion \"sadness\":\n",
      "mic.: 0.71;\t mac.:0.62\n",
      "\n",
      "Emotion \"anger\":\n",
      "mic.: 0.76;\t mac.:0.57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lexicon approach\n",
    "\n",
    "print('Lexicon approach:\\n')\n",
    "\n",
    "for emo_label in emo_lexicon_dict.keys():\n",
    "    true_y, pred_y = [], []\n",
    "\n",
    "    for sample in test_df:\n",
    "        if emo_label in sample['labels']:\n",
    "            true_y.append(1)\n",
    "        else:\n",
    "            true_y.append(0)\n",
    "        \n",
    "        # The emotion label is determined by thepresence of words from \n",
    "        # the emotive vocabulary for the corresponding emotion\n",
    "        sample_lemms = [word['lemma'].lower() for sentence in sample['sentences'] for word in sentence]        \n",
    "        if any(word in emo_lexicon_dict[emo_label] for word in sample_lemms):\n",
    "            pred_y.append(1)\n",
    "        else:\n",
    "            pred_y.append(0)\n",
    "    \n",
    "    # The accuracy of the obtained models is measured with the F1 metric\n",
    "    p_micro, r_micro, f_micro, _ = metrics.precision_recall_fscore_support(true_y, pred_y, average=\"micro\")\n",
    "    p_macro, r_macro, f_macro, _ = metrics.precision_recall_fscore_support(true_y, pred_y, average=\"macro\")\n",
    "    \n",
    "    print(f'Emotion \"{emo_label}\":')\n",
    "    print(f'mic.: {round(f_micro, 2)};\\t mac.:{round(f_macro, 2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc1c9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(TF-IDF) model:\n",
      "\n",
      "Emotion \"surprise\":\n",
      "mic.: 0.93;\t mac.:0.67\n",
      "\n",
      "Emotion \"fear\":\n",
      "mic.: 0.94;\t mac.:0.66\n",
      "\n",
      "Emotion \"joy\":\n",
      "mic.: 0.86;\t mac.:0.67\n",
      "\n",
      "Emotion \"sadness\":\n",
      "mic.: 0.86;\t mac.:0.71\n",
      "\n",
      "Emotion \"anger\":\n",
      "mic.: 0.93;\t mac.:0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM + (TF-IDF)\n",
    "\n",
    "print('SVM(TF-IDF) model:\\n')\n",
    "\n",
    "# TF-IDF features\n",
    "vect = TfidfVectorizer(analyzer='char', ngram_range=(4,8))\n",
    "texts_for_fit = [sample['text'].lower() for sample in train_df]\n",
    "texts_for_fit += [sample['text'].lower() for sample in test_df]\n",
    "vect.fit(texts_for_fit)\n",
    "\n",
    "# SVM model with linear kernel\n",
    "model = LinearSVC(random_state=42)\n",
    "\n",
    "for emo_label in emo_lexicon_dict.keys():\n",
    "    train_x, test_x = [], []\n",
    "    train_y, true_y = [], []\n",
    "    pred_y = []\n",
    "    \n",
    "    for sample in train_df:\n",
    "        train_x.append(sample['text'].lower())\n",
    "        \n",
    "        if emo_label in sample['labels']:\n",
    "            train_y.append(1)\n",
    "        else:\n",
    "            train_y.append(0)\n",
    "\n",
    "    train_x = vect.transform(train_x)\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    for sample in test_df:\n",
    "        test_x.append(sample['text'].lower())\n",
    "        \n",
    "        if emo_label in sample['labels']:\n",
    "            true_y.append(1)\n",
    "        else:\n",
    "            true_y.append(0)\n",
    "    \n",
    "    test_x = vect.transform(test_x)\n",
    "    pred_y = model.predict(test_x)\n",
    "    \n",
    "    # The accuracy of the obtained models is measured with the F1 metric\n",
    "    p_micro,r_micro,f_micro,_ = metrics.precision_recall_fscore_support(true_y, pred_y, average=\"micro\")\n",
    "    p_macro,r_macro,f_macro,_ = metrics.precision_recall_fscore_support(true_y, pred_y, average=\"macro\")\n",
    "    \n",
    "    print(f'Emotion \"{emo_label}\":')\n",
    "    print(f'mic.: {round(f_micro, 2)};\\t mac.:{round(f_macro, 2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648a0bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our approach:\n",
      "\n",
      "Emotion \"surprise\":\n",
      "mic.: 0.93;\t mac.:0.76\n",
      "\n",
      "Emotion \"fear\":\n",
      "mic.: 0.93;\t mac.:0.73\n",
      "\n",
      "Emotion \"joy\":\n",
      "mic.: 0.92;\t mac.:0.87\n",
      "\n",
      "Emotion \"sadness\":\n",
      "mic.: 0.92;\t mac.:0.86\n",
      "\n",
      "Emotion \"anger\":\n",
      "mic.: 0.9;\t mac.:0.62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Our approach (ensemble + ELMO embedding vectors)\n",
    "\n",
    "print('Our approach:\\n')\n",
    "\n",
    "# After the adjustment and comparison of the classifiers, \n",
    "# the final solution is an ensemble of the following five binaryclassifiers:\n",
    "\n",
    "# 1. A model based on gradient descent and logistic regression methods, \n",
    "# with preliminarynormalization of the data: the ratio of the difference in value and \n",
    "# its mean to standard deviation\n",
    "surprise_model = load_model('../models/surprise_model.pkl')\n",
    "\n",
    "# 2. A model based on stochastic gradient descent with PCA preprocessing of input features\n",
    "fear_model = load_model('../models/fear_model.pkl')\n",
    "\n",
    "# 3. A model based on logistic regression\n",
    "sad_model = load_model('../models/sad_model.pkl')\n",
    "\n",
    "# 4. A model based on a support vector machine with a linear kernel\n",
    "joy_model = load_model('../models/joy_model.pkl')\n",
    "\n",
    "# 5. A model based on logistic regression\n",
    "anger_model = load_model('../models/anger_model.pkl')\n",
    "\n",
    "# load ELMO embedding vectors\n",
    "df = load_model('../data/elmo_vec.pkl')\n",
    "\n",
    "for emo_label in emo_lexicon_dict.keys():\n",
    "    if emo_label == 'surprise':\n",
    "        model = surprise_model\n",
    "    elif emo_label == 'fear':\n",
    "        model = fear_model\n",
    "    elif emo_label == 'sadness':\n",
    "        model = sad_model\n",
    "    elif emo_label == 'joy':\n",
    "        model = joy_model\n",
    "    elif emo_label == 'anger':\n",
    "        model = anger_model\n",
    "        \n",
    "    train_x, train_y = [], []\n",
    "    test_x, test_y = [], []\n",
    "    \n",
    "    for sample in df['train']:\n",
    "        train_x.append(sample['vec'])\n",
    "        if emo_label in sample['labels']:\n",
    "            train_y.append(1)\n",
    "        else:\n",
    "            train_y.append(0)\n",
    "\n",
    "    for sample in df['test']:\n",
    "        test_x.append(sample['vec'])\n",
    "        if emo_label in sample['labels']:\n",
    "            test_y.append(1)\n",
    "        else:\n",
    "            test_y.append(0)\n",
    "    \n",
    "    pred_y = model.predict(np.array(test_x))\n",
    "\n",
    "    p_micro,r_micro,f_micro,_ = metrics.precision_recall_fscore_support(test_y, pred_y, average=\"micro\")\n",
    "    p_macro,r_macro,f_macro,_ = metrics.precision_recall_fscore_support(test_y, pred_y, average=\"macro\")\n",
    "    \n",
    "    print(f'Emotion \"{emo_label}\":')\n",
    "    print(f'mic.: {round(f_micro, 2)};\\t mac.:{round(f_macro, 2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dab35bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful complete\n"
     ]
    }
   ],
   "source": [
    "print(\"Successful complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.7.0, cedr_v0.0.1)",
   "language": "python",
   "name": "git_cedr_v001"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
